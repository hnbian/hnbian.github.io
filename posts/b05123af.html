<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Spark SQL 1. 常见概念与基本操作, hnbian">
    <meta name="description" content="1. SparkSQL 概述1.1 Shark
Shark 是 Databricks 开发出专门针对于spark的构建大规模数据仓库系统的一个框架

Shark 与 Hive 兼容，同时也依赖于Spark版本

Shark是把sql语句解析">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-155985521-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());
    gtag('config', 'UA-155985521-1');
</script>


    <title>Spark SQL 1. 常见概念与基本操作 | hnbian</title>
    <link rel="icon" type="image/png" href="https://images.hnbian.cn/FvNSAGx7xljxALFh8Fa2DPNFP-JB">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="hnbian" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="stylesheet" href="/css/prism-okaidia.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="https://images.hnbian.cn/FvNSAGx7xljxALFh8Fa2DPNFP-JB" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">hnbian</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="https://images.hnbian.cn/FvNSAGx7xljxALFh8Fa2DPNFP-JB" class="logo-img circle responsive-img">
        
        <div class="logo-name">hnbian</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/hnbian" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/hnbian" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://images.hnbian.cn/FrN4vbzEBFOBMcrYy2Bf6m1fzizs')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Spark SQL 1. 常见概念与基本操作</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/spark/">
                                <span class="chip bg-color">spark</span>
                            </a>
                        
                            <a href="/tags/spark-sql/">
                                <span class="chip bg-color">spark sql</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/spark/" class="post-category">
                                spark
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2018-05-21
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="1-SparkSQL-概述"><a href="#1-SparkSQL-概述" class="headerlink" title="1. SparkSQL 概述"></a>1. SparkSQL 概述</h2><h3 id="1-1-Shark"><a href="#1-1-Shark" class="headerlink" title="1.1 Shark"></a>1.1 Shark</h3><ul>
<li><p>Shark 是 Databricks 开发出专门针对于spark的构建大规模数据仓库系统的一个框架</p>
</li>
<li><p>Shark 与 Hive 兼容，同时也依赖于Spark版本</p>
</li>
<li><p>Shark是把sql语句解析成了Spark任务，Hivesql 底层把 sql 解析成了 mapreduce 程序</p>
</li>
<li><p>随着对 Shark 性能优化的上限，以及集成SQL的一些复杂的分析功能，发现Hive的MapReduce思想限制了Shark的发展</p>
</li>
<li><p>最后 Databricks 公司终止对 Shark 的开发,决定单独开发一个框架，不在依赖hive，把重点转移到了 <code>SparkSQL</code> 这个框架上</p>
</li>
</ul>
<h3 id="1-2-SparkSQL-是什么"><a href="#1-2-SparkSQL-是什么" class="headerlink" title="1.2 SparkSQL 是什么"></a>1.2 SparkSQL 是什么</h3><blockquote>
<p><strong>Spark SQL</strong> is Apache Spark’s module for working with structured data.</p>
<p>SparkSQL是apache Spark用来处理结构化数据的一个模块</p>
</blockquote>
<h3 id="1-3-SparkSQL-的特性"><a href="#1-3-SparkSQL-的特性" class="headerlink" title="1.3 SparkSQL 的特性"></a>1.3 SparkSQL 的特性</h3><ol>
<li>易整合</li>
</ol>
<ul>
<li>SparkSQL将SQL查询与Spark程序无缝混合</li>
<li>SparkSQL 可以使用java、Scala、Python、R 等不同的语言进行代码开发</li>
</ul>
<p><img src="https://images.hnbian.cn/FpDTSRGMyFrOzpYoPau64DYH_awe?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim"></p>
<ol start="2">
<li>统一的数据源访问</li>
</ol>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 以相同的方式连接到任何数据源</span></span><br><span class="line"><span class="keyword">val</span>  dataFrame = sparkSession.read.文件格式的方法名(<span class="string">"该文件格式的路径"</span>)</span><br></pre></td></tr></tbody></table></figure>

<p><img src="https://images.hnbian.cn/Fo1o1-4_UnsOxN3qxZWvNEGnBqZ0?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim"></p>
<ol start="3">
<li>兼容hive</li>
</ol>
<p>SparkSQL 可以支持 HiveSql 这种语法</p>
<p><img src="https://images.hnbian.cn/FuSwAP6N2JjtyVO5HAgavpznNG7t?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim"></p>
<ol start="4">
<li>支持标准的数据库连接</li>
</ol>
<p>SparkSQL支持标准的数据库连接JDBC或者ODBC</p>
<p><img src="https://images.hnbian.cn/FqpOCVp8_tM-n5WUx1kaarI6STfV?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim"></p>
<h2 id="2-DataFrame"><a href="#2-DataFrame" class="headerlink" title="2. DataFrame"></a>2. DataFrame</h2><h3 id="2-1-DataFrame的由来"><a href="#2-1-DataFrame的由来" class="headerlink" title="2.1 DataFrame的由来"></a>2.1 DataFrame的由来</h3><ul>
<li>DataFrame 前身是 schemaRDD，schemaRDD 是RDD的一个实现类，直接继承自 RDD</li>
<li>在spark1.3.0之后把 schemaRDD 改名为 DataFrame，它不在继承自RDD，而是自己实现RDD上的一些功能</li>
<li>DataFrame也可以调用rdd方法将其转换成一个rdd</li>
</ul>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1=dataFrame.rdd</span><br></pre></td></tr></tbody></table></figure>



<h3 id="2-2-DataFrame是什么"><a href="#2-2-DataFrame是什么" class="headerlink" title="2.2 DataFrame是什么"></a>2.2 DataFrame是什么</h3><ul>
<li>DataFrame 是Spark中一种 以RDD为基础的分布式数据集，类似于传统数据库的表格</li>
<li>DataFrame 带有 <strong>Schema元信息</strong>，即DataFrame所表示的二维表数据集的每一列都带有名称和类型，但底层做了更多的优化</li>
<li>DataFrame 可以从很多数据源构建，比如：已经存在的RDD、结构化文件、外部数据库、Hive表</li>
<li>DataFrame 可以把内部是一个Row对象，它表示一行一行的数据（RDD可以把它内部元素看成是一个java对象）</li>
<li>DataFrame 相比于rdd来说，多了对数据的描述的schema元信息</li>
</ul>
<img src="https://images.hnbian.cn/FqlIgAucPRNnctXD5WM5zYuJtEae?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" style="zoom:50%;">



<h3 id="2-3-DataFrame和RDD的对比"><a href="#2-3-DataFrame和RDD的对比" class="headerlink" title="2.3 DataFrame和RDD的对比"></a>2.3 DataFrame和RDD的对比</h3><h4 id="2-3-1-RDD"><a href="#2-3-1-RDD" class="headerlink" title="2.3.1 RDD"></a>2.3.1 RDD</h4><ul>
<li><strong>优点</strong></li>
</ul>
<ol>
<li><p>编译时类型安全开发会进行类型检查</p>
</li>
<li><p>在编译的时候及时发现错误 具有面向对象编程的风格</p>
</li>
</ol>
<ul>
<li><strong>缺点</strong></li>
</ul>
<ol>
<li>构建大量的java对象占用了大量heap堆空间，导致频繁的GC</li>
</ol>
<p>由于数据集RDD它的数据量比较大，后期都需要存储在heap堆中，这里有heap堆中的内存空间有限，出现频繁的垃圾回收（GC），程序在进行垃圾回收的过程中，所有的任务都是暂停。影响程序执行的效率</p>
<ol start="2">
<li>数据的序列化和反序列性能开销很大</li>
</ol>
<p> 在分布式程序中，对象(对象的内容和结构)是先进行序列化，发送到其他服务器，进行大量的网络传输，然后接受到这些序列化的数据之后，再进行反序列化来恢复该对象</p>
<h4 id="2-3-2-DataFrame"><a href="#2-3-2-DataFrame" class="headerlink" title="2.3.2 DataFrame"></a>2.3.2 DataFrame</h4><ul>
<li><strong>优点</strong></li>
</ul>
<ol>
<li>DataFrame 引入off-heap（堆外内存） ，大量的对象构建直接使用操作系统层面上的内存，不在使用heap堆中的内存，这样一来heap堆中的内存空间就比较充足，不会导致频繁GC，程序的运行效率比较高，它是解决了RDD构建大量的java对象占用了大量heap堆空间，导致频繁的GC这个缺点。</li>
<li>DataFrame 引入了schema元信息，就是数据结构的描述信息，后期spark程序中的大量对象在进行网络传输的时候，只需要把数据的内容本身进行序列化就可以，数据结构信息可以省略掉。这样一来数据网络传输的数据量是有所减少，数据的序列化和反序列性能开销就不是很大了。它是解决了RDD数据的序列化和反序列性能开销很大这个缺点</li>
</ol>
<ul>
<li><strong>缺点</strong></li>
</ul>
<p>DataFrame引入了schema元信息和off-heap(堆外)它是分别解决了RDD的缺点，同时它也丢失了RDD的优点</p>
<ol>
<li>编译时类型不安全，编译时不会进行类型的检查，这里也就意味着前期是无法在编译的时候发现错误，只有在运行的时候才会发现</li>
<li>不在具有面向对象编程的风格</li>
</ol>
<h3 id="2-4-构建DataFrame"><a href="#2-4-构建DataFrame" class="headerlink" title="2.4 构建DataFrame"></a>2.4 构建DataFrame</h3><p>前提工作</p>
<figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1. 将数据文件传到服务器上</span></span><br><span class="line">scp dataFile userName@serverNode:/path</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">dataFile 数据文件</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">username 登录到服务器的用户名</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">serverNode 将数据上传到哪台服务器</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">path 保存数据的路径</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2. 进入 spark Home 目录</span></span><br><span class="line">cd /opt/spark-2.3.3-bin-hadoop2.7/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3. 启动 spark shell</span></span><br><span class="line">bin/spark-shell  --master local[2] --jars /opt/hadoop-2.6.0-cdh5.14.2/share/hadoop/common/hadoop-lzo-0.4.20.jar</span><br></pre></td></tr></tbody></table></figure>



<h4 id="2-4-1-通过文本创建-DataFrame"><a href="#2-4-1-通过文本创建-DataFrame" class="headerlink" title="2.4.1 通过文本创建 DataFrame"></a>2.4.1 通过文本创建 DataFrame</h4><figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">val</span> personDF=spark.read.text(<span class="string">"file:///sparkdatas/person.txt"</span>)</span><br><span class="line"><span class="comment">//org.apache.spark.sql.DataFrame = [value: string]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//打印schema信息</span></span><br><span class="line">personDF.printSchema</span><br><span class="line"></span><br><span class="line"><span class="comment">//展示数据</span></span><br><span class="line">personDF.show</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>



<ul>
<li>将文本转换成对象，再转换成 DataFrame</li>
</ul>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//加载数据</span></span><br><span class="line"><span class="keyword">val</span> rdd1=sc.textFile(<span class="string">"file:///sparkdatas/person.txt"</span>).map(x=&gt;x.split(<span class="string">" "</span>))</span><br><span class="line"><span class="comment">//定义一个样例类</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">id:<span class="type">String</span>,name:<span class="type">String</span>,age:<span class="type">Int</span></span>)</span></span><br><span class="line"><span class="comment">//把rdd与样例类进行关联</span></span><br><span class="line"><span class="keyword">val</span> personRDD=rdd1.map(x=&gt;<span class="type">Person</span>(x(<span class="number">0</span>),x(<span class="number">1</span>),x(<span class="number">2</span>).toInt))</span><br><span class="line"><span class="comment">//把rdd转换成DataFrame</span></span><br><span class="line"><span class="keyword">val</span> personDF=personRDD.toDF</span><br><span class="line"></span><br><span class="line"><span class="comment">//打印schema信息</span></span><br><span class="line">personDF.printSchema</span><br><span class="line"><span class="comment">//展示数据</span></span><br><span class="line">personDF.show</span><br></pre></td></tr></tbody></table></figure>



<h4 id="2-4-2-通过JSON文件创建-DataFrame"><a href="#2-4-2-通过JSON文件创建-DataFrame" class="headerlink" title="2.4.2 通过JSON文件创建 DataFrame"></a>2.4.2 通过JSON文件创建 DataFrame</h4><figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> df1=spark.read.json(<span class="string">"file:///sparkdatas/person.json"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//打印schema信息</span></span><br><span class="line">df1.printSchema</span><br><span class="line"></span><br><span class="line"><span class="comment">//展示数据</span></span><br><span class="line">df1.show</span><br></pre></td></tr></tbody></table></figure>



<h4 id="2-4-3-通过Parquet创建-DataFrame"><a href="#2-4-3-通过Parquet创建-DataFrame" class="headerlink" title="2.4.3 通过Parquet创建 DataFrame"></a>2.4.3 通过Parquet创建 DataFrame</h4><figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> df2=spark.read.parquet(<span class="string">"file:///sparkdatas/person.parquet"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//打印schema信息</span></span><br><span class="line">df2.printSchema</span><br><span class="line"></span><br><span class="line"><span class="comment">//展示数据</span></span><br><span class="line">df2.show</span><br></pre></td></tr></tbody></table></figure>



<h3 id="2-5-DataFrame-API"><a href="#2-5-DataFrame-API" class="headerlink" title="2.5 DataFrame API"></a>2.5 DataFrame API</h3><h4 id="2-5-1-引入依赖"><a href="#2-5-1-引入依赖" class="headerlink" title="2.5.1 引入依赖"></a>2.5.1 引入依赖</h4><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.avro<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>avro-mapred<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.commons<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-lang3<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.7<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.6.0-mr1-cdh5.14.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.zookeeper<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>zookeeper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.0-cdh5.14.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.0-cdh5.14.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure>



<h4 id="2-5-2-常用-API-示例"><a href="#2-5-2-常用-API-示例" class="headerlink" title="2.5.2 常用 API 示例"></a>2.5.2 常用 API 示例</h4><ul>
<li>DataFrame API</li>
</ul>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.{<span class="type">SparkConf</span>, <span class="type">SparkContext</span>}</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//定义 Person 样例类</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">id:<span class="type">String</span>,name:<span class="type">String</span>,age:<span class="type">Int</span></span>)</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkDSL</span> </span>{</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = {</span><br><span class="line">    <span class="keyword">val</span> sparkConf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[2]"</span>).setAppName(<span class="string">"sparkDSL"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> sparkSession: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder().config(sparkConf).getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sc: <span class="type">SparkContext</span> = sparkSession.sparkContext</span><br><span class="line">    sc.setLogLevel(<span class="string">"WARN"</span>)</span><br><span class="line">    <span class="comment">//加载数据</span></span><br><span class="line">    <span class="keyword">val</span> rdd1=sc.textFile(<span class="string">"file:///D:\\datas/person.txt"</span>).map(x=&gt;x.split(<span class="string">" "</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//把rdd与样例类进行关联</span></span><br><span class="line">    <span class="keyword">val</span> personRDD=rdd1.map(x=&gt;<span class="type">Person</span>(x(<span class="number">0</span>),x(<span class="number">1</span>),x(<span class="number">2</span>).toInt))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 隐式转换</span></span><br><span class="line">    <span class="keyword">import</span> sparkSession.implicits._  </span><br><span class="line">    </span><br><span class="line">    <span class="comment">//把rdd转换成DataFrame</span></span><br><span class="line">    <span class="keyword">val</span> personDF=personRDD.toDF</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//打印schema信息</span></span><br><span class="line">    personDF.printSchema</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//展示数据</span></span><br><span class="line">    personDF.show</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询指定的字段</span></span><br><span class="line">    personDF.select(<span class="string">"name"</span>).show</span><br><span class="line">    personDF.select($<span class="string">"name"</span>).show</span><br><span class="line"></span><br><span class="line">    <span class="comment">//实现age+1</span></span><br><span class="line">    personDF.select($<span class="string">"name"</span>,$<span class="string">"age"</span>,$<span class="string">"age"</span>+<span class="number">1</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//实现age大于30过滤</span></span><br><span class="line">    personDF.filter($<span class="string">"age"</span> &gt; <span class="number">30</span>).show</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照age分组统计次数</span></span><br><span class="line">    personDF.groupBy(<span class="string">"age"</span>).count.show</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照age分组统计次数降序</span></span><br><span class="line">    personDF.groupBy(<span class="string">"age"</span>).count().sort($<span class="string">"count"</span>.desc).show</span><br><span class="line"></span><br><span class="line">    sparkSession.stop()</span><br><span class="line">    sc.stop()</span><br><span class="line">  }</span><br><span class="line">} </span><br></pre></td></tr></tbody></table></figure>

<ul>
<li>SQL 风格语法</li>
</ul>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.{<span class="type">SparkConf</span>, <span class="type">SparkContext</span>}</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//定义 Person 样例类</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">id:<span class="type">String</span>,name:<span class="type">String</span>,age:<span class="type">Int</span></span>)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//可以把DataFrame注册成一张表，然后通过 sparkSession.sql(sql语句) 操作</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkDSL</span> </span>{</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = {</span><br><span class="line">    <span class="keyword">val</span> sparkConf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[2]"</span>).setAppName(<span class="string">"sparkDSL"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> sparkSession: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder().config(sparkConf).getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sc: <span class="type">SparkContext</span> = sparkSession.sparkContext</span><br><span class="line">    sc.setLogLevel(<span class="string">"WARN"</span>)</span><br><span class="line">    <span class="comment">//加载数据</span></span><br><span class="line">    <span class="keyword">val</span> rdd1=sc.textFile(<span class="string">"file:///D:\\datas/person.txt"</span>).map(x=&gt;x.split(<span class="string">" "</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//把rdd与样例类进行关联</span></span><br><span class="line">    <span class="keyword">val</span> personRDD=rdd1.map(x=&gt;<span class="type">Person</span>(x(<span class="number">0</span>),x(<span class="number">1</span>),x(<span class="number">2</span>).toInt))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 隐式转换</span></span><br><span class="line">    <span class="keyword">import</span> sparkSession.implicits._  </span><br><span class="line"></span><br><span class="line">    <span class="comment">//把rdd转换成DataFrame</span></span><br><span class="line">    <span class="keyword">val</span> personDF=personRDD.toDF</span><br><span class="line"></span><br><span class="line">    <span class="comment">//打印schema信息</span></span><br><span class="line">    personDF.printSchema</span><br><span class="line"></span><br><span class="line">    <span class="comment">//展示数据</span></span><br><span class="line">    personDF.show</span><br><span class="line"></span><br><span class="line">    <span class="comment">//DataFrame注册成表</span></span><br><span class="line">    personDF.createTempView(<span class="string">"person"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用SparkSession调用sql方法统计查询</span></span><br><span class="line">    spark.sql(<span class="string">"select * from person"</span>).show</span><br><span class="line">    spark.sql(<span class="string">"select name from person"</span>).show</span><br><span class="line">    spark.sql(<span class="string">"select name,age from person"</span>).show</span><br><span class="line">    spark.sql(<span class="string">"select * from person where age &gt;30"</span>).show</span><br><span class="line">    spark.sql(<span class="string">"select count(*) from person where age &gt;30"</span>).show</span><br><span class="line">    spark.sql(<span class="string">"select age,count(*) from person group by age"</span>).show</span><br><span class="line">    spark.sql(<span class="string">"select age,count(*) as count from person group by age"</span>).show</span><br><span class="line">    spark.sql(<span class="string">"select * from person order by age desc"</span>).show</span><br><span class="line">    </span><br><span class="line">    sparkSession.stop()</span><br><span class="line">    sc.stop()</span><br><span class="line">  }</span><br><span class="line">} </span><br></pre></td></tr></tbody></table></figure>



<h2 id="3-DataSet"><a href="#3-DataSet" class="headerlink" title="3. DataSet"></a>3. DataSet</h2><h3 id="3-1-DataSet是什么"><a href="#3-1-DataSet是什么" class="headerlink" title="3.1 DataSet是什么"></a>3.1 DataSet是什么</h3><ul>
<li>DataSet 是分布式的数据集合，Dataset提供了 <strong>强类型支持</strong>，也是在RDD的每行数据加了类型约束。</li>
<li>DataSet 是在Spark1.6中添加的新的接口，它集中了RDD的优点，强类型和可以用强大lambda函数以及使用了Spark SQL优化的执行引擎。</li>
<li>DataSet 包含了 DataFrame 的功能，Spark2.0中两者统一</li>
<li>DataFrame 表示为DataSet[Row]，即DataSet的子集</li>
<li>DataSet可以在编译时检查类型，并且是面向对象的编程接口。</li>
</ul>
<h4 id="3-2-构建-DataSet"><a href="#3-2-构建-DataSet" class="headerlink" title="3.2 构建 DataSet"></a>3.2 构建 DataSet</h4><ol>
<li>通过sparkSession调用createDataset方法</li>
</ol>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> ds = spark.createDataset(<span class="number">1</span> to <span class="number">10</span>) <span class="comment">//scala集合</span></span><br><span class="line"><span class="keyword">val</span> ds = spark.createDataset(sc.textFile(<span class="string">"/person.txt"</span>))  <span class="comment">//rdd</span></span><br></pre></td></tr></tbody></table></figure>



<ol start="2">
<li>使用scala集合和rdd调用toDS方法</li>
</ol>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sc.textFile(<span class="string">"/person.txt"</span>).toDS</span><br><span class="line"><span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>).toDS</span><br></pre></td></tr></tbody></table></figure>



<ol start="3">
<li>把一个DataFrame转换成DataSet</li>
</ol>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val dataSet=dataFrame.as[强类型]</span><br></pre></td></tr></tbody></table></figure>



<ol start="4">
<li>通过一个DataSet转换生成一个新的DataSet</li>
</ol>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>).toDS.map(x=&gt;x*<span class="number">10</span>)</span><br></pre></td></tr></tbody></table></figure>





<h3 id="3-2-RDD-DataFrame-DataSet的区别与联系"><a href="#3-2-RDD-DataFrame-DataSet的区别与联系" class="headerlink" title="3.2 RDD,DataFrame,DataSet的区别与联系"></a>3.2 RDD,DataFrame,DataSet的区别与联系</h3><p>Spark RDD、DataFrame和DataSet是Spark的三类API，DataFrame是spark1.3.0版本提出来的，spark1.6.0版本又引入了DateSet的，但是在spark2.0版本中，DataFrame和DataSet合并为DataSet。</p>
<img src="https://images.hnbian.cn/FsP-FO0xM2VOk7JpAlPS1iZkyBdI?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim" style="zoom:50%;">



<h4 id="3-2-1-RDD"><a href="#3-2-1-RDD" class="headerlink" title="3.2.1 RDD"></a>3.2.1 RDD</h4><ul>
<li>优点</li>
</ul>
<ol>
<li>相比于传统的MapReduce框架，Spark在RDD中内置很多函数操作，group，map，filter等，方便处理结构化或非结构化数据</li>
<li>面向对象编程，直接存储的java对象，类型转化也安全</li>
</ol>
<ul>
<li>缺点</li>
</ul>
<ol>
<li>由于它基本和hadoop一样万能的，因此没有针对特殊场景的优化，比如对于结构化数据处理相对于sql来比非常麻烦</li>
<li>默认采用的是java序列号方式，序列化结果比较大，而且数据存储在java堆内存中，导致gc比较频繁</li>
</ol>
<h4 id="3-2-2DataFrame"><a href="#3-2-2DataFrame" class="headerlink" title="3.2.2DataFrame"></a>3.2.2DataFrame</h4><ul>
<li>优点</li>
</ul>
<ol>
<li><p>结构化数据处理非常方便，支持Avro, CSV, elastic search, and Cassandra等kv数据，也支持HIVE tables, MySQL等传统数据表</p>
</li>
<li><p>有针对性的优化，如采用Kryo序列化，由于数据结构元信息spark已经保存，序列化时不需要带上元信息，大大的减少了序列化大小，而且数据保存在堆外内存中，减少了gc次数,所以运行更快。</p>
</li>
<li><p>hive兼容，支持hql、udf等</p>
</li>
</ol>
<ul>
<li>缺点</li>
</ul>
<ol>
<li>编译时不能类型转化安全检查，运行时才能确定是否有问题</li>
<li>对于对象支持不友好，rdd内部数据直接以java对象存储，dataframe内存存储的是row对象而不能是自定义对象</li>
</ol>
<h4 id="3-2-3-DateSet"><a href="#3-2-3-DateSet" class="headerlink" title="3.2.3 DateSet"></a>3.2.3 DateSet</h4><ul>
<li>优点</li>
</ul>
<ol>
<li>DateSet整合了RDD和DataFrame的优点，支持结构化和非结构化数据</li>
<li>和RDD一样，支持自定义对象存储</li>
<li>和DataFrame一样，支持结构化数据的sql查询</li>
<li>采用堆外内存存储，gc友好</li>
<li>类型转化安全，代码友好</li>
</ol>
<h3 id="3-3-RDD-DataFrame-DataSet数据结构"><a href="#3-3-RDD-DataFrame-DataSet数据结构" class="headerlink" title="3.3 RDD,DataFrame,DataSet数据结构"></a>3.3 RDD,DataFrame,DataSet数据结构</h3><p><img src="https://images.hnbian.cn/Fr3zaM_6Pa5Z1odAOLHd_PJ1Yzib?imageView2/0/interlace/1/q/70%7Cwatermark/2/text/d3d3LmhuYmlhbi5jbg==/font/5b6u6L2v6ZuF6buR/fontsize/600/fill/IzBDMjU2NA==/dissolve/100/gravity/SouthEast/dx/10/dy/10%7Cimageslim"></p>
<h2 id="4-DataFrame-DataSet转换"><a href="#4-DataFrame-DataSet转换" class="headerlink" title="4. DataFrame,DataSet转换"></a>4. DataFrame,DataSet转换</h2><h3 id="4-1-介绍转换方式"><a href="#4-1-介绍转换方式" class="headerlink" title="4.1 介绍转换方式"></a>4.1 介绍转换方式</h3><ol>
<li>把一个DataFrame转换成DataSet</li>
</ol>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataSet = dataFrame.as[强类型]</span><br></pre></td></tr></tbody></table></figure>



<ol start="2">
<li>把一个DataSet转换成DataFrame</li>
</ol>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dataFrame=dataSet.toDF</span><br></pre></td></tr></tbody></table></figure>



<ol start="3">
<li>可以从dataFrame和dataSet获取得到rdd</li>
</ol>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1=dataFrame.rdd</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> rdd2=dataSet.rdd</span><br></pre></td></tr></tbody></table></figure>



<h3 id="4-2-测试代码"><a href="#4-2-测试代码" class="headerlink" title="4.2 测试代码"></a>4.2 测试代码</h3><h4 id="4-2-1-利用反射机制"><a href="#4-2-1-利用反射机制" class="headerlink" title="4.2.1 利用反射机制"></a>4.2.1 利用反射机制</h4><p>通常应用在在开发代码之前，是可以先确定好DataFrame的schema元信息的情况。</p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义一个样例类，后期直接映射成DataFrame的schema信息</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">id:<span class="type">String</span>,name:<span class="type">String</span>,age:<span class="type">Int</span></span>)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.{<span class="type">Column</span>, <span class="type">DataFrame</span>, <span class="type">Row</span>, <span class="type">SparkSession</span>}</span><br><span class="line"></span><br><span class="line"><span class="comment">//todo:利用反射机制实现把rdd转成dataFrame</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">id:<span class="type">String</span>,name:<span class="type">String</span>,age:<span class="type">Int</span></span>)</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">CaseClassSchema</span> </span>{</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = {</span><br><span class="line"></span><br><span class="line">    <span class="comment">//1、构建SparkSession对象</span></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder().appName(<span class="string">"CaseClassSchema"</span>).master(<span class="string">"local[2]"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2、获取sparkContext对象</span></span><br><span class="line">    <span class="keyword">val</span> sc: <span class="type">SparkContext</span> = spark.sparkContext</span><br><span class="line">    sc.setLogLevel(<span class="string">"warn"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3、读取文件数据</span></span><br><span class="line">    <span class="keyword">val</span> data: <span class="type">RDD</span>[<span class="type">Array</span>[<span class="type">String</span>]] = sc.textFile(<span class="string">"file:///D:\\datas"</span>).map(x=&gt;x.split(<span class="string">" "</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4、定义一个样例类</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//5、将rdd与样例类进行关联</span></span><br><span class="line">    <span class="keyword">val</span> personRDD: <span class="type">RDD</span>[<span class="type">Person</span>] = data.map(x=&gt;<span class="type">Person</span>(x(<span class="number">0</span>),x(<span class="number">1</span>),x(<span class="number">2</span>).toInt))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//6、将rdd转换成dataFrame</span></span><br><span class="line">    <span class="comment">//需要手动导入隐式转换</span></span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    <span class="keyword">val</span> personDF: <span class="type">DataFrame</span> = personRDD.toDF</span><br><span class="line"></span><br><span class="line">    <span class="comment">//7、对dataFrame进行相应的语法操作</span></span><br><span class="line">    <span class="comment">//todo：----------------- DSL风格语法-----------------start</span></span><br><span class="line">    <span class="comment">//打印schema</span></span><br><span class="line">    personDF.printSchema()</span><br><span class="line">    <span class="comment">//展示数据</span></span><br><span class="line">    personDF.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取第一行数据</span></span><br><span class="line">    <span class="keyword">val</span> first: <span class="type">Row</span> = personDF.first()</span><br><span class="line">    println(<span class="string">"first:"</span>+first)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//取出前3位数据</span></span><br><span class="line">    <span class="keyword">val</span> top3: <span class="type">Array</span>[<span class="type">Row</span>] = personDF.head(<span class="number">3</span>)</span><br><span class="line">    top3.foreach(println)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取name字段</span></span><br><span class="line">    personDF.select(<span class="string">"name"</span>).show()</span><br><span class="line">    personDF.select($<span class="string">"name"</span>).show()</span><br><span class="line">    personDF.select(<span class="keyword">new</span> <span class="type">Column</span>(<span class="string">"name"</span>)).show()</span><br><span class="line">    personDF.select(<span class="string">"name"</span>,<span class="string">"age"</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//实现age +1</span></span><br><span class="line">    personDF.select($<span class="string">"name"</span>,$<span class="string">"age"</span>,$<span class="string">"age"</span>+<span class="number">1</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照age过滤</span></span><br><span class="line">    personDF.filter($<span class="string">"age"</span> &gt;<span class="number">30</span>).show()</span><br><span class="line">    <span class="keyword">val</span> count: <span class="type">Long</span> = personDF.filter($<span class="string">"age"</span> &gt;<span class="number">30</span>).count()</span><br><span class="line">    println(<span class="string">"count:"</span>+count)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//分组</span></span><br><span class="line">    personDF.groupBy(<span class="string">"age"</span>).count().show()</span><br><span class="line"></span><br><span class="line">    personDF.show()</span><br><span class="line">    personDF.foreach(row =&gt; println(row))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用foreach获取每一个row对象中的name字段</span></span><br><span class="line">    personDF.foreach(row =&gt;println(row.getAs[<span class="type">String</span>](<span class="string">"name"</span>)))</span><br><span class="line">    personDF.foreach(row =&gt;println(row.get(<span class="number">1</span>)))</span><br><span class="line">    personDF.foreach(row =&gt;println(row.getString(<span class="number">1</span>)))</span><br><span class="line">    personDF.foreach(row =&gt;println(row.getAs[<span class="type">String</span>](<span class="number">1</span>)))</span><br><span class="line">    <span class="comment">//todo：----------------- DSL风格语法--------------------end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//todo：----------------- SQL风格语法-----------------start</span></span><br><span class="line">    personDF.createTempView(<span class="string">"person"</span>)</span><br><span class="line">    <span class="comment">//使用SparkSession调用sql方法统计查询</span></span><br><span class="line">    spark.sql(<span class="string">"select * from person"</span>).show</span><br><span class="line">    spark.sql(<span class="string">"select name from person"</span>).show</span><br><span class="line">    spark.sql(<span class="string">"select name,age from person"</span>).show</span><br><span class="line">    spark.sql(<span class="string">"select * from person where age &gt;30"</span>).show</span><br><span class="line">    spark.sql(<span class="string">"select count(*) from person where age &gt;30"</span>).show</span><br><span class="line">    spark.sql(<span class="string">"select age,count(*) from person group by age"</span>).show</span><br><span class="line">    spark.sql(<span class="string">"select age,count(*) as count from person group by age"</span>).show</span><br><span class="line">    spark.sql(<span class="string">"select * from person order by age desc"</span>).show</span><br><span class="line">    <span class="comment">//todo：----------------- SQL风格语法----------------------end</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//关闭sparkSession对象</span></span><br><span class="line">    spark.stop()</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>

<p>4.2.2 通过StructType动态指定Schema</p>
<p>通常应用在，在开发代码之前，是无法确定需要的DataFrame对应的schema元信息的情况。需要在开发代码的过程中动态指定。</p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.{<span class="type">IntegerType</span>, <span class="type">StringType</span>, <span class="type">StructField</span>, <span class="type">StructType</span>}</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.{<span class="type">DataFrame</span>, <span class="type">Row</span>, <span class="type">SparkSession</span>}</span><br><span class="line"></span><br><span class="line"><span class="comment">//todo；通过动态指定dataFrame对应的schema信息将rdd转换成dataFrame</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">StructTypeSchema</span> </span>{</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = {</span><br><span class="line">    <span class="comment">//1、构建SparkSession对象</span></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder().appName(<span class="string">"StructTypeSchema"</span>).master(<span class="string">"local[2]"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2、获取sparkContext对象</span></span><br><span class="line">    <span class="keyword">val</span> sc: <span class="type">SparkContext</span> = spark.sparkContext</span><br><span class="line">    sc.setLogLevel(<span class="string">"warn"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3、读取文件数据</span></span><br><span class="line">    <span class="keyword">val</span> data: <span class="type">RDD</span>[<span class="type">Array</span>[<span class="type">String</span>]] = sc.textFile(<span class="string">"file:///D:\\datas"</span>).map(x=&gt;x.split(<span class="string">" "</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4、将rdd与Row对象进行关联</span></span><br><span class="line">    <span class="keyword">val</span> rowRDD: <span class="type">RDD</span>[<span class="type">Row</span>] = data.map(x=&gt;<span class="type">Row</span>(x(<span class="number">0</span>),x(<span class="number">1</span>),x(<span class="number">2</span>).toInt))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//5、指定dataFrame的schema信息</span></span><br><span class="line">    <span class="comment">//这里指定的字段个数和类型必须要跟Row对象保持一致</span></span><br><span class="line">    <span class="keyword">val</span> schema=<span class="type">StructType</span>(</span><br><span class="line">      <span class="type">StructField</span>(<span class="string">"id"</span>,<span class="type">StringType</span>)::</span><br><span class="line">        <span class="type">StructField</span>(<span class="string">"name"</span>,<span class="type">StringType</span>)::</span><br><span class="line">        <span class="type">StructField</span>(<span class="string">"age"</span>,<span class="type">IntegerType</span>)::<span class="type">Nil</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> dataFrame: <span class="type">DataFrame</span> = spark.createDataFrame(rowRDD,schema)</span><br><span class="line">    dataFrame.printSchema()</span><br><span class="line">    dataFrame.show()</span><br><span class="line"></span><br><span class="line">    dataFrame.createTempView(<span class="string">"user"</span>)</span><br><span class="line">    spark.sql(<span class="string">"select * from user"</span>).show()</span><br><span class="line">    spark.stop()</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>



<h2 id="5-SparkSQL-读取与写入数据示例"><a href="#5-SparkSQL-读取与写入数据示例" class="headerlink" title="5. SparkSQL 读取与写入数据示例"></a>5. SparkSQL 读取与写入数据示例</h2><h3 id="5-1-SparkSQL读取sql数据"><a href="#5-1-SparkSQL读取sql数据" class="headerlink" title="5.1 SparkSQL读取sql数据"></a>5.1 SparkSQL读取sql数据</h3><p>spark sql可以通过 JDBC 从关系型数据库中读取数据的方式创建DataFrame，通过对DataFrame一系列的计算后，还可以将数据再写回关系型数据库中</p>
<ul>
<li>添加mysql连接驱动jar包</li>
</ul>
<figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>5.1.38<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure>

<ul>
<li>代码开发</li>
</ul>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.{<span class="type">DataFrame</span>, <span class="type">SparkSession</span>}</span><br><span class="line"></span><br><span class="line"><span class="comment">//todo:利用sparksql加载mysql表中的数据</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DataFromMysql</span> </span>{</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = {</span><br><span class="line">    <span class="comment">//1、创建SparkConf对象</span></span><br><span class="line">    <span class="keyword">val</span> sparkConf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"DataFromMysql"</span>).setMaster(<span class="string">"local[2]"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2、创建SparkSession对象</span></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder().config(sparkConf).getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3、读取mysql表的数据</span></span><br><span class="line">    <span class="comment">//3.1 指定mysql连接地址</span></span><br><span class="line">    <span class="keyword">val</span> url=<span class="string">"jdbc:mysql://localhost:3306/mydb?characterEncoding=UTF-8"</span></span><br><span class="line">    <span class="comment">//3.2 指定要加载的表名</span></span><br><span class="line">    <span class="keyword">val</span> tableName=<span class="string">"jobdetail"</span></span><br><span class="line">    <span class="comment">// 3.3 配置连接数据库的相关属性</span></span><br><span class="line">    <span class="keyword">val</span> properties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//用户名</span></span><br><span class="line">    properties.setProperty(<span class="string">"user"</span>,<span class="string">"root"</span>)</span><br><span class="line">    <span class="comment">//密码</span></span><br><span class="line">    properties.setProperty(<span class="string">"password"</span>,<span class="string">"123456"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> mysqlDF: <span class="type">DataFrame</span> = spark.read.jdbc(url,tableName,properties)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//打印schema信息</span></span><br><span class="line">    mysqlDF.printSchema()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//展示数据</span></span><br><span class="line">    mysqlDF.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//把dataFrame注册成表</span></span><br><span class="line">    mysqlDF.createTempView(<span class="string">"job_detail"</span>)</span><br><span class="line"></span><br><span class="line">    spark.sql(<span class="string">"select * from job_detail where city = '广东' "</span>).show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>



<h3 id="5-2-sparkSQL读取CSV文建写入MySQL"><a href="#5-2-sparkSQL读取CSV文建写入MySQL" class="headerlink" title="5.2 sparkSQL读取CSV文建写入MySQL"></a>5.2 sparkSQL读取CSV文建写入MySQL</h3><p>使用spark程序读取CSV文件，然后将读取到的数据内容，保存到mysql里面去，注意csv文件的换行问题。</p>
<figure class="highlight scala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.{<span class="type">DataFrame</span>, <span class="type">SaveMode</span>, <span class="type">SparkSession</span>}</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">CSVOperate</span> </span>{</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = {</span><br><span class="line">    <span class="keyword">val</span> sparkConf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[8]"</span>).setAppName(<span class="string">"sparkCSV"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> session: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder().config(sparkConf).getOrCreate()</span><br><span class="line">    session.sparkContext.setLogLevel(<span class="string">"WARN"</span>)</span><br><span class="line">    <span class="keyword">val</span> frame: <span class="type">DataFrame</span> = session</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">"csv"</span>)</span><br><span class="line">      .option(<span class="string">"timestampFormat"</span>, <span class="string">"yyyy/MM/dd HH:mm:ss ZZ"</span>)</span><br><span class="line">      .option(<span class="string">"header"</span>, <span class="string">"true"</span>)</span><br><span class="line">      .option(<span class="string">"multiLine"</span>, <span class="literal">true</span>)</span><br><span class="line">      .load(<span class="string">"file:///D:\\datas"</span>)</span><br><span class="line"></span><br><span class="line">    frame.createOrReplaceTempView(<span class="string">"job_detail"</span>)</span><br><span class="line">    <span class="keyword">val</span> prop = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">    prop.put(<span class="string">"user"</span>, <span class="string">"root"</span>)</span><br><span class="line">    prop.put(<span class="string">"password"</span>, <span class="string">"123456"</span>)</span><br><span class="line"></span><br><span class="line">    frame.write.mode(<span class="type">SaveMode</span>.<span class="type">Append</span>).jdbc(<span class="string">"jdbc:mysql://localhost:3306/mydb?useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8"</span>, <span class="string">"mydb.jobdetail_copy"</span>, prop)</span><br><span class="line"></span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>


                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">hnbian</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://www.hnbian.cn/posts/b05123af.html">https://www.hnbian.cn/posts/b05123af.html</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">hnbian</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/spark/">
                                    <span class="chip bg-color">spark</span>
                                </a>
                            
                                <a href="/tags/spark-sql/">
                                    <span class="chip bg-color">spark sql</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    
        <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }

    #vcomments textarea {
        box-sizing: border-box;
        background: url("/medias/comment_bg.png") 100% 100% no-repeat;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #4cbf30;
        font-weight: 500;
        text-decoration: none;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; padding-left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="vcomments" class="card-content" style="display: grid">
    </div>
</div>

<script src="/libs/valine/av-min.js"></script>
<script src="/libs/valine/Valine.min.js"></script>
<script>
    new Valine({
        el: '#vcomments',
        appId: 'h1rND3bHC0OqFwzm1UfPQpaY-gzGzoHsz',
        appKey: 'd7uboDt2WLV2HJCEMHkkLuU4',
        serverURLs: '',
        notify: 'false' === 'true',
        verify: 'false' === 'true',
        visitor: 'true' === 'true',
        avatar: 'identicon',
        pageSize: '12',
        lang: 'zh-cn',
        placeholder: 'just go go'
    });
</script>

<!--酷Q推送-->


    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/posts/191f89ce.html">
                    <div class="card-image">
                        
                        <img src="https://images.hnbian.cn/FktuT8T4IIkKdmZRBmQFjPeEczEd" class="responsive-img" alt="Spark SQL 2.自定义函数">
                        
                        <span class="card-title">Spark SQL 2.自定义函数</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2018-05-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/spark/" class="post-category">
                                    spark
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/spark/">
                        <span class="chip bg-color">spark</span>
                    </a>
                    
                    <a href="/tags/spark-sql/">
                        <span class="chip bg-color">spark sql</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/posts/247ba11b.html">
                    <div class="card-image">
                        
                        <img src="https://images.hnbian.cn/FrN4vbzEBFOBMcrYy2Bf6m1fzizs" class="responsive-img" alt="Spark SQL 自适应执行实践">
                        
                        <span class="card-title">Spark SQL 自适应执行实践</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2018-05-20
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/spark/" class="post-category">
                                    spark
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/spark/">
                        <span class="chip bg-color">spark</span>
                    </a>
                    
                    <a href="/tags/spark-sql/">
                        <span class="chip bg-color">spark sql</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE' || selection.getRangeAt(0).commonAncestorContainer.nodeName === 'CODE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: hnbian<br />'
            + '文章作者: hnbian<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4, h5'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2018-2025</span>
            
            <a href="/about" target="_blank">hnbian</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
                <span id="translate">|&nbsp;繁/简：</span><a id="translateLink" href="javascript:translatePage();">繁</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2018";
                        var startMonth = "2";
                        var startDate = "8";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
                <span id="icp"><img src="/medias/icp.png"
                                    style="vertical-align: text-bottom;"/>
                <a href="https://beian.miit.gov.cn" target="_blank">粤ICP备18156920号-2</a>
            </span>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/hnbian" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:hnbian@126.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
        <script type="text/javascript" src="/js/tw_cn.js"></script>
        <script type="text/javascript">
          var defaultEncoding = 2; //网站编写字体是否繁体，1-繁体，2-简体
          var translateDelay = 0; //延迟时间,若不在前, 要设定延迟翻译时间, 如100表示100ms,默认为0
          var cookieDomain = "https://www.hnbian.cn"; //Cookie地址, 一定要设定, 通常为你的网址
          var msgToTraditionalChinese = "繁"; //此处可以更改为你想要显示的文字
          var msgToSimplifiedChinese = "简"; //同上，但两处均不建议更改
          var translateButtonId = "translateLink"; //默认互换id
          translateInitilization();
        </script>
    
    
    

    <!-- 雪花特效 -->
     
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/snow.js"><\/script>');
            }
        </script>
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
